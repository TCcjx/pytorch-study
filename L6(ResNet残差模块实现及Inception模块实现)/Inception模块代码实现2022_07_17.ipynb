{
 "cells": [
  {
   "cell_type": "raw",
   "id": "928801d5",
   "metadata": {},
   "source": [
    "Inception 混合几种不同尺寸的卷积网络，对特征进行提取\n",
    "1.一层block就包含1x1卷积，3x3卷积，5x5卷积，3x3池化\n",
    "网络中每层都能学习到稀疏或者不稀疏的特征，再合并特征"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f13a0e0",
   "metadata": {},
   "source": [
    "在Inception结构中，大量采用1x1的矩阵，主要是两点作用：\n",
    "（1）对数据进行降维\n",
    "（2）引入更多的非线性，提高泛化能力，因为卷积后要经过RelU激活函数\n",
    "1x1 卷积代替Linear层减少模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "713c146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2834cc2",
   "metadata": {},
   "source": [
    "定义基础卷积模型： 卷积 + BN + 激活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29c7919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basic_conv2d(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,**kwargs):\n",
    "        super(Basic_conv2d,self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels,out_channels,bias=False,**kwargs)\n",
    "        self.BN = nn.BatchNorm2d(out_channels)\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46dfd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self,in_channels,pool_features):\n",
    "        super(InceptionBlock,self).__init__()\n",
    "        self.b1x1 = Basic_conv2d(in_channels,64,kernel_size = 1)\n",
    "              \n",
    "        self.b3x3_1 = Basic_conv2d(in_channels,64,kernel_size = 1)\n",
    "        self.b3x3_2 = Basic_conv2d(64,96,kernel_size = 3,padding=1)      \n",
    "        \n",
    "        self.b5x5_1 = Basic_conv2d(in_channels,48,kernel_size = 1)\n",
    "        self.b5x5_2 = Basic_conv2d(48,64,kernel_size=2) #保持图像大小不变，使用padding填充\n",
    "       \n",
    "        self.b_pool = Basic_conv2d(in_channels,pool_features,kernel_size=1)\n",
    "    def forward(self,x):\n",
    "        b_1x1_out = self.b1x1(x)\n",
    "        b_3x3 = self.b3x3_1(x)\n",
    "        b_3x3_out = self.b3x3_2(b_3x3) \n",
    "        b_5x5 = self.b5x5_1(x)\n",
    "        b_5x5_out = self.b5x5_2(b_5x5)\n",
    "        b_pool_out = F.max_pool2d(x,kernel_size=3,stride=1,padding=1) #保持大小不变\n",
    "        b_pool_out = self.b_pool(b_pool_out)\n",
    "        \n",
    "        outputs = [b_1x1_out,b_3x3_out,b_5x5_out,b_pool_out]\n",
    "        return torch.cat(outputs,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01fa150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionBlock(\n",
       "  (b1x1): Basic_conv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b3x3_1): Basic_conv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b3x3_2): Basic_conv2d(\n",
       "    (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (BN): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b5x5_1): Basic_conv2d(\n",
       "    (conv): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BN): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b5x5_2): Basic_conv2d(\n",
       "    (conv): Conv2d(48, 64, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "    (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b_pool): Basic_conv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_inception = InceptionBlock(32,64)\n",
    "my_inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8969a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py",
   "language": "python",
   "name": "pytorch_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
